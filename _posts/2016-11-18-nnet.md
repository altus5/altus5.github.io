---
layout: post
title:  "ニューラルネットワークの考え方とライブラリ"
date:   2016-11-18 16:11:44 +0000
categories: blog machine-learning
---
## Google の翻訳機能
 
11月12日、GoogleはGoogle翻訳の日本語の機能のアップグレードを実施し、「精度が良すぎる」と大きく話題になりました。  
例えば、

> From the Canadian Registry of patients with Upper Gastrointestinal Bleeding and Endoscopy (RUGBE), we determined clinical outcomes and explored the roles of endoscopic and pharmacologic therapies in a contemporary real-life setting.  
（引用：http://www.nature.com/ajg/journal/v99/n7/abs/ajg2004245a.html）  

こちらの文章をGoogle 翻訳にかけると  

> 上消化管出血と内視鏡検査（RUGBE）患者のカナダ登録簿から、臨床結果を決定し、現代の現実の環境における内視鏡的および薬理学的療法の役割を探った。

と何とも素晴らしい翻訳結果になりました。

こちらはある論文のabstract部分なのですが、このぐらいしっかり書かれた文章（ブログなどの適当な文章ではなく）であれば、かなり正確な翻訳をしてくれます。

機能改善前は、思わず笑っちゃうような翻訳が多かったGoogle翻訳ですが、どうしてここまで精度が上がったのでしょうか?

それには、ニューラルネットワークという数学モデルの働きがあります。

## ニューラルネットワーク
![ニューラルネットワーク]({% asset_path blog/NN-1.png %})

図のように、脳はある入力を受けると各神経細胞（ニューロン）へ信号を送り、その神経細胞は受け取った情報を処理すると、他の神経細胞へまたその情報を送ります。それらを繰り返し、最終的に出力（理解）を行います。  
例えば翻訳の例で言うと、英語の文章の入力を得て日本語の文章を出力（理解）する。また、ある動物園のある写真を見て（入力）、この写真に写っている動物がライオンだと判断（出力）する、などもありますね。  
ニューラルネットワークとは、このように人間が物事を判断する際の脳の神経伝達の働きを参考にして、落とし込んだ数学モデルです。  

40年代から既に研究されていた分野ですが、近年ITによりデータ数が莫大に増加したことや、ニューラルネットワークの精度を上げる新しい手法に対する研究が進んだことで、近年大きく取り上げられ始めました。  
特に前述したような言語処理や画像認識、音声処理の分野で注目が集まっています。  

またニューラルネットワークは、順伝播型ニューラルネットワーク（FFNN）・畳み込みニューラルネットワーク（CNN）・再起型ニューラルネットワーク（RNN）に大きく分けられます。  

基本のアイデアとなるのがFFNN、それを応用させたのがCNNとRNNという理解で良いと思います。  
今回は基本のFFNNの考えについて簡単に説明し、最後にライブラリについて紹介するというところまでやっていきます。

## FFNN
FFNN（順伝播型ニューラルネットワーク）のイメージ図を貼り付けます。  
![ニューラルネットワーク]({% asset_path blog/NN-2.png %})

まず、ニューラルネットワークを用いるうえで必要な用語を簡単に勉強しましょう。  
先程の脳で考えた、各神経細胞一つ一つを「ユニット」と呼びます。  
そして、各段階のユニットの集まりを「層（layer）」と呼びます。  

大きな括りで言うと、層から層へ流れ、最終的にある出力がなされ、細かく言うとその層から層への流れはユニット間の働きで決まります。  

現在は入力から出力までの層は2つですが、この層の数は任意に決めることができます。  
![ニューラルネットワーク]({% asset_path blog/NN-3.png %})

このように多層にすることも可能です。  

またここで、図2のユニット間の繋がりを見て、隣接層のユニット同士が全て結合している状態（全結合）であることに注目してください。  
これがニューラルネットワークの基本となるFFNN（順伝播型ニューラルネットワーク）です。  

もし、全てのユニットが結合せず、下図のようであればFFNNとは呼ばず、これはCNN（畳み込みニューラルネットワーク）と呼びます。  
![ニューラルネットワーク]({% asset_path blog/NN-4.png %})

今回は詳しく説明を行いませんが、CNNはその特性から画像認識の分野で大きく成果を上げている手法です。  

### FFNNのモデル
説明を簡略化するために下図のように簡単なモデルを考え、FFNNの解き方を説明していきます。  
![ニューラルネットワーク]({% asset_path blog/NN-5.png %})

#### Step1：次の層へ信号を送る
まず入力 $$ x $$ を受け取ると隣接する3つのユニットへ信号が送られます。  
この時、各ユニットへは重み $$ w $$ が掛けられ、その値は $$ u $$ として保存されます。  

$$ u_1^1 = w_1^1 * x $$

$$ u_2^1 = w_2^1 * x $$

$$ u_3^1 = w_3^1 * x $$

となります。

#### Step2：次の層へ送る出力を計算
受け取った入力（ $$ u $$ ）から、次の層へ送る出力（ $$ z $$ ）を計算します。  

$$ z_1^1 = f(u_1^1) $$

$$ z_2^1 = f(u_2^1) $$

$$ z_3^1 = f(u_3^1) $$

この $$ f $$ とは活性化関数と呼ばれる関数で、扱う人によって様々な関数系を用いることができます。  
最近では,  

$$ f(u) = max(u,0) $$

という関数系を使って推定を行う方が多いようです。  

#### Step3：Step1とStep2の繰り返し
Step2で次の層へ送る出力を計算できたら、Step1と同様にその結果を次の層へ送る。  
これを最後の層まで繰り返します。  

### 誤差を最小にするパラメーターを求める
これまでで、どのようにFFNNが動いているかイメージがついたと思います。  
途中で重みを掛けたり、活性化関数を通す処理を繰り返し、最終的に出力された $$ y $$ が実際の出力とどれだけ差があるか（誤差）を計算します。  

この誤差が小さければ小さいほど精度が良い、ということになります。  

さらっと流した「重み」という概念ですが、とても大切で、この重みを調整することで、最終的な誤差を小さくすることができます。  
「この重みの値を大きく、また小さく、今度はあの重みを大きく……」というふうに調整していきます。  

そして最も誤差が小さくなるようにパラメーターが調節できれば、FFNNの働きは終了。  

実際には、入力や出力がただの数値ではなく、音声だったり画像だったりしますし、重みパラメータの調節のためには、
難しいアルゴリズムが裏で実行することになりますが、根本的なニューラルネットワークのアイデアは、これでOKかと思います。  

## ニューラルネットワークを使えるライブラリ
裏側で動くアルゴリズムまで理解して実行することが理想ですが、その辺りはライブラリに頼る人が実際のところ多いそうです。
ということで、いくつか言語別にライブラリを紹介していきます。  

機械学習を行う言語として有名なのが、ライブラリの豊富なPythonやR。  

Pythonで使えるライブラリだと TensorflowやChainer、Theanoが有名です。  

Rで使えるライブラリだと、nnetがあります。  
この2つを使うのが無難かと思いますが、Rの場合は画像処理がしづらいので、画像処理まで扱いたいという場合はPythonを選択するのが良いでしょう。  

ちなみにJava で書きたい、という方にはdeeplearning4j というライブラリがオススメです。顔/画像認識や音声検索、音声の文字化もできて、上記のニューラルネットワークもすぐに活用することができます。  

RやPythonに比べて、参考になる資料が少ない印象を受けますが、チュートリアルがあるので、気になる方はそちらを見ながら [deeplearning4j](https://deeplearning4j.org/index.html) 
進めてみてはいかがでしょうか？  

## 弊社の取り組み

さて、弊社での機械学習やAIへの取り組みについて、ご紹介します。  
弊社は、あくまで、システム屋なので、上記にあるようなライブラリをうまく使いこなして、
迅速にシステムへの導入を行うということが、役割となります。  
これまでにも、機械学習を活用したレコメンドエンジンの導入や、クローラーと、
テキストマイニングを組み合わせた、クチコミの分析システムの開発などを、行ってきました。

機械学習系のライブラリの情報量は、例えば、Spring や Lalavel などと比較すると、
前者の方が、圧倒的に少ないので、使いこなすまでには、何度となく、ライブラリのソースコードの中を、
読むことにもなり、なかなか、歯ごたえのある仕事です。  
そして、思ったほど、精度が出ないことが、ほとんどなので、そこから、試行錯誤が始まります。  
試行錯誤するために、機械学習の仕組みを知っていた方が、有利なので、雑学程度の勉強も必要となります。

ライブラリを使いこなしたり、アイデアを捻出して試行錯誤を繰り返すので、
そういうことが、好きな人には、楽しい仕事だと思います。

ディープラーニングも、とても、興味深く見ています。  
まだ、ディープラーニングを使ったシステムを開発したことはありませんが、
Chainer の研修には、社員の何人かは、参加していました。

いつか、ディープラーニングを使った、 chatbot など、作ってみたいです。
