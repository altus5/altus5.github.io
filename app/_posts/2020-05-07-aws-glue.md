---
layout: app/_layouts/post.html.ejs
title:  "AWS Glueのローカル環境を作成する"
date:   2020-02-17 06:00:00 +0900
categories: blog etl
description: "Sparkが使えるAWSのサービス(AWS Glue)を使うことになったとき、開発時にかかるGlueの利用料を抑えるために、ローカルに開発環境を作ります。"
tags:
- "AWS"
- "Glue"
- "Spark"
---

AWS 上に構築されたシステム間で、データ変換と連携処理を行う開発を行いました。

連携データは S3 上に csv と json 形式で、何種類かのデータを使います。  
取り込んだデータは、最終的には、 Athena で検索することに使われるんですが、元データの量が大きいため、効率よく短時間で取り込むために Spark が使いたいなぁという状況でした。  
ただ、24時間常時実行される仕組みではないので Spark のためだけに複数台の EC2 を使うのはモッタイないです。  
夜間バッチの1～2時間くらい使えればよいので Spark そのものが、サービス化されたものってないのかしら・・・と、AWSを探したところ AWS Glue がズバリそのものでした。

### AWS Glue のお試し

さっそく、 Glue をシステムに組み込めそうか、お試しすることにしました。  
CSV を Parquet 形式に変換するところに Glue を使ってみます。そして、おぉ、やっぱり速い！  
ついでに Parquet 形式になったデータを Athena で検索してみても、おぉ、これも速い！  
・・・ということを体感して、イケそうな感触が得られたので、本格的な開発の準備に取り掛かかることにしました。

### 料金を気にせず開発したい

Spark の開発をやったことのある方ならわかると思うのですが Spark は 大量のメモリを使うので、そのクラスター構成を動かすサービスとなると、利用料も安いハズがないです。  
バグで暴走して、ものすごい請求が来た！なんてことになると困ります。ジョブを停止する手順をあらかじめ調べておいて、いざというときには、強制停止できるように準備しておく必要があります。  
でも、それでも、”ジョブを実行”する段階では、ビビります。特に開発チームに参加したばかりの人は、実行ボタンを推すときの躊躇いの時間が、初期の立ちあがりの時間を遅くします。

プログラム作りは、ちょっと実装して動かしてみて軌道修正して・・・という作業を繰り返すので、”ためらう”ことなく実行できるローカルの環境があると、安心して試行に取り組めます。

## AWS Glue をローカルで動かす

そんなわけで、dockerで実行できるようにしました。  

参考にしたのは、この2つの記事です。  
<https://dev.classmethod.jp/articles/aws-glue-local/>  
<https://future-architect.github.io/articles/20191101/>  

作成した dockerイメージは、[Docker Hub](https://hub.docker.com/repository/docker/altus5/devcontainer-glue) で公開してあります。

Dockerfile は以下のようになりました。

- Glue 1.0 は Python 3.6
- PySparkを使うために、python:3.6 のイメージを元にしている
- vscode のリモートコンテナで使うようにしてある
- Spark は JDK8 じゃないとダメ（デフォルトのJDK10ではエラーが出る）
- gluepyspark を1回動かしてmavenの依存モジュールをイメージに入れておく
- jarの参照先をsparkのものに入れ替える

```dockerfile
FROM python:3.6

# Avoid warnings by switching to noninteractive
ENV DEBIAN_FRONTEND=noninteractive

ENV PYTHONUNBUFFERED 1

# This Dockerfile adds a non-root user with sudo access. Use the "remoteUser"
# property in devcontainer.json to use it. On Linux, the container user's GID/UIDs
# will be updated to match your local UID/GID (when using the dockerFile property).
# See https://aka.ms/vscode-remote/containers/non-root-user for details.
ARG USERNAME=vscode
ARG USER_UID=1000
ARG USER_GID=$USER_UID

# Configure apt and install packages
RUN echo 'deb http://ftp.us.debian.org/debian sid main' >> /etc/apt/sources.list \
    && apt-get update \
    && apt-get -y install --no-install-recommends apt-utils dialog 2>&1 \
    #
    # Verify git, process tools, lsb-release (common in install instructions for CLIs) installed
    && apt-get -y install git iproute2 procps lsb-release \
    #
    # Install pylint
    && pip --disable-pip-version-check --no-cache-dir install pylint \
    #
    # Update Python environment based on requirements.txt
    # && pip --disable-pip-version-check --no-cache-dir install -r /tmp/pip-tmp/requirements.txt \
    # && rm -rf /tmp/pip-tmp \
    #
    # Create a non-root user to use if preferred - see https://aka.ms/vscode-remote/containers/non-root-user.
    && groupadd --gid $USER_GID $USERNAME \
    && useradd -s /bin/bash --uid $USER_UID --gid $USER_GID -m $USERNAME \
    # [Optional] Add sudo support for the non-root user
    && apt-get install -y sudo \
    && echo $USERNAME ALL=\(root\) NOPASSWD:ALL > /etc/sudoers.d/$USERNAME\
    && chmod 0440 /etc/sudoers.d/$USERNAME \
    # for glue (spark=jdk8)
    && apt-get install -y openjdk-8-jdk zip unzip \
    #
    # Create alternate global install location that both uses have rights to access
    # && mkdir -p /usr/local/share/pip-global \
    # && chown ${USERNAME}:root /usr/local/share/pip-global \
    #
    # Clean up
    && apt-get autoremove -y \
    && apt-get clean -y \
    && rm -rf /var/lib/apt/lists/*

# awscli
RUN curl -sSL "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
RUN unzip awscliv2.zip
RUN ./aws/install

# maven
RUN curl -sSOL https://aws-glue-etl-artifacts.s3.amazonaws.com/glue-common/apache-maven-3.6.0-bin.tar.gz
RUN tar -xzvf apache-maven-3.6.0-bin.tar.gz
RUN mv apache-maven-3.6.0 /opt/
RUN ln -s /opt/apache-maven-3.6.0 /opt/apache-maven
ENV PATH $PATH:/opt/apache-maven/bin

# glue 1.0
RUN git clone -b glue-1.0 --depth 1 https://github.com/awslabs/aws-glue-libs
RUN mv aws-glue-libs /opt/
ENV chmod -R ao+wr /opt/aws-glue-libs
ENV PATH $PATH:/opt/aws-glue-libs/bin

# spark
RUN curl -OL https://aws-glue-etl-artifacts.s3.amazonaws.com/glue-1.0/spark-2.4.3-bin-hadoop2.8.tgz
RUN tar -xzvf spark-2.4.3-bin-hadoop2.8.tgz 
RUN mv spark-2.4.3-bin-spark-2.4.3-bin-hadoop2.8 /opt/
RUN ln -s /opt/spark-2.4.3-bin-spark-2.4.3-bin-hadoop2.8 /opt/spark
ENV SPARK_HOME /opt/spark

# glue setup
RUN gluepyspark

RUN mv /opt/aws-glue-libs/jarsv1 /opt/aws-glue-libs/jarsv1.bk
RUN ln -s ${SPARK_HOME}/jars /opt/aws-glue-libs/jarsv1

```

docker-compose.yml も作成します。
のちのち、LocalStackも入れたくなるでしょう。  

```yml
version: '3'
services:
  glue:
    image: altus5/devcontainer-glue:latest
    volumes:
      - '.:/workspace'
    working_dir: '/workspace'
    environment:
      TZ: 'Asia/Tokyo'
    command: 'sleep infinity'

```

`docker-compose up -d` で起動させたら glue のコンテナ内に入ります。

```bash
docker-compose exec glue bash
```

実行するには、それぞれのアカウントを設定して、テストデータを配置して、 glue にスクリプトを送信します。

```bash
export AWS_ACCESS_KEY_ID=XXXXXXXXXXXXXX
export AWS_SECRET_ACCESS_KEY=YYYYYYYYYYY
export AWS_REGION=ap-northeast-1

# S3にテストデータ配置（コピーするデータは適宜自分で用意する）
aws s3 cp testdata.gz s3://glue-test/

# 実行
gluesparksubmit ./src/sample.py --JOB_NAME='dummy'

```
